{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-e34972428f84>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  X = pd.read_csv(\"../Datasets/emojified_text/emojify_train_x.csv\", header=None, sep=\"' '\")\n",
      "<ipython-input-152-e34972428f84>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  Xt = pd.read_csv(\"../Datasets/emojified_text/emojiy_test_x.csv\", header=None, sep=\"' '\")\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"../Datasets/emojified_text/emojify_train_x.csv\", header=None, sep=\"' '\")\n",
    "Y = pd.read_csv(\"../Datasets/emojified_text/Emojify_Y_train.csv\", header=None, sep=' ')\n",
    "\n",
    "Xt = pd.read_csv(\"../Datasets/emojified_text/emojiy_test_x.csv\", header=None, sep=\"' '\")\n",
    "Yt = pd.read_csv(\"../Datasets/emojified_text/emojiy_y_test.csv\", header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.asarray(X, dtype=str).reshape((-1,1))\n",
    "Ytrain = np.asarray(Y, dtype=int).reshape((-1,1))\n",
    "\n",
    "Xtest = np.asarray(Xt, dtype=str).reshape((-1,1))\n",
    "Ytest = Yt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_idx = {}\n",
    "\n",
    "with open(\"../Datasets/glove.6B.50d.txt/glove.6B.50d.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word_values = line.split()\n",
    "        word = word_values[0]\n",
    "        values = np.asarray(word_values[1:], dtype='float')\n",
    "        embedding_idx[word] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    \"0\": \":red_heart:\",\n",
    "    \"1\": \":baseball:\",\n",
    "    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "    \"3\": \":disappointed_face:\",\n",
    "    \"4\": \":fork_and_knife:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❤️'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(emoji_dict[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sentences in embedding format\n",
    "def data_embedding(X):\n",
    "    datasize = X.shape[0]\n",
    "    maxlen = 10 # sentences will be clipped after 10 words\n",
    "    \n",
    "    embed_data = list()\n",
    "    for sent in X:\n",
    "        sent = sent.split()\n",
    "        embed_sent = list()\n",
    "        for w_idx in range(maxlen):\n",
    "            try:\n",
    "                word = sent[w_idx].lower()\n",
    "                embed_sent.append(embedding_idx[word])\n",
    "            except:\n",
    "                embed_sent.append(np.zeros((50,)))\n",
    "                \n",
    "        embed_data.append(np.asarray(embed_sent))\n",
    "    \n",
    "    return np.asarray(embed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_emb = data_embedding(Xtrain[:,0])\n",
    "Xtest_emb = data_embedding(Xtest[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'never talk to me again\""
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RNN/LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 145       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,405\n",
      "Trainable params: 31,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(10, 50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(28,  activation='relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-f3586019f1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentiment-analysis-model.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mZ:\\Google\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', mode='max', patience=2)\n",
    "checkpoint = ModelCheckpoint(\"sentiment-analysis-model.h5\", verbose=1, monitor='val_accuracy', mode='max', save_weights_only=True, )\n",
    "\n",
    "hist = model.fit(Xtrain_emb, Ytrain, batch_size=10, epochs=20, callbacks=[earlystop, checkpoint], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert Ytrain into one-hot format\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Ytrain_oht = to_categorical(Ytrain)\n",
    "Ytest_oht = to_categorical(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3366 - accuracy: 0.3810\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 1.3366 - accuracy: 0.3810 - val_loss: 1.3930 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2759 - accuracy: 0.5048\n",
      "Epoch 2: val_accuracy did not improve from 0.33333\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.2759 - accuracy: 0.5048 - val_loss: 1.4469 - val_accuracy: 0.2593\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2345 - accuracy: 0.4381\n",
      "Epoch 3: val_accuracy improved from 0.33333 to 0.37037, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 1.2345 - accuracy: 0.4381 - val_loss: 1.3040 - val_accuracy: 0.3704\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1249 - accuracy: 0.6286\n",
      "Epoch 4: val_accuracy did not improve from 0.37037\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.1249 - accuracy: 0.6286 - val_loss: 1.3224 - val_accuracy: 0.2963\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.0631 - accuracy: 0.5619\n",
      "Epoch 5: val_accuracy improved from 0.37037 to 0.44444, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0631 - accuracy: 0.5619 - val_loss: 1.2233 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9519 - accuracy: 0.6667\n",
      "Epoch 6: val_accuracy did not improve from 0.44444\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.9519 - accuracy: 0.6667 - val_loss: 1.2104 - val_accuracy: 0.4074\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9705 - accuracy: 0.6571\n",
      "Epoch 7: val_accuracy improved from 0.44444 to 0.48148, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.9705 - accuracy: 0.6571 - val_loss: 1.1361 - val_accuracy: 0.4815\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.6762\n",
      "Epoch 8: val_accuracy did not improve from 0.48148\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.8735 - accuracy: 0.6762 - val_loss: 1.1786 - val_accuracy: 0.4815\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7238\n",
      "Epoch 9: val_accuracy improved from 0.48148 to 0.55556, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8087 - accuracy: 0.7238 - val_loss: 1.0105 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8442 - accuracy: 0.7048\n",
      "Epoch 10: val_accuracy did not improve from 0.55556\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.8442 - accuracy: 0.7048 - val_loss: 1.4550 - val_accuracy: 0.4074\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7742 - accuracy: 0.7524\n",
      "Epoch 11: val_accuracy did not improve from 0.55556\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.7742 - accuracy: 0.7524 - val_loss: 0.9692 - val_accuracy: 0.5185\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.8095\n",
      "Epoch 12: val_accuracy improved from 0.55556 to 0.66667, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.6829 - accuracy: 0.8095 - val_loss: 1.0152 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.7619\n",
      "Epoch 13: val_accuracy did not improve from 0.66667\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.7276 - accuracy: 0.7619 - val_loss: 1.0287 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.8000\n",
      "Epoch 14: val_accuracy did not improve from 0.66667\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.5978 - accuracy: 0.8000 - val_loss: 1.0371 - val_accuracy: 0.5185\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.8381\n",
      "Epoch 15: val_accuracy did not improve from 0.66667\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.5714 - accuracy: 0.8381 - val_loss: 1.1054 - val_accuracy: 0.5926\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7905\n",
      "Epoch 16: val_accuracy did not improve from 0.66667\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.5776 - accuracy: 0.7905 - val_loss: 1.2457 - val_accuracy: 0.5556\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8571\n",
      "Epoch 17: val_accuracy did not improve from 0.66667\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.5052 - accuracy: 0.8571 - val_loss: 0.9452 - val_accuracy: 0.5926\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8571\n",
      "Epoch 18: val_accuracy improved from 0.66667 to 0.70370, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.4526 - accuracy: 0.8571 - val_loss: 0.9947 - val_accuracy: 0.7037\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.8286\n",
      "Epoch 19: val_accuracy improved from 0.70370 to 0.74074, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4769 - accuracy: 0.8286 - val_loss: 0.8155 - val_accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.9048\n",
      "Epoch 20: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.4326 - accuracy: 0.9048 - val_loss: 1.6346 - val_accuracy: 0.4815\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.8000\n",
      "Epoch 21: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.5341 - accuracy: 0.8000 - val_loss: 0.9460 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.9048\n",
      "Epoch 22: val_accuracy improved from 0.74074 to 0.77778, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.3546 - accuracy: 0.9048 - val_loss: 0.7894 - val_accuracy: 0.7778\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8857\n",
      "Epoch 23: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.3496 - accuracy: 0.8857 - val_loss: 0.9124 - val_accuracy: 0.6296\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.9048\n",
      "Epoch 24: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.3190 - accuracy: 0.9048 - val_loss: 0.9014 - val_accuracy: 0.7037\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8952\n",
      "Epoch 25: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.2984 - accuracy: 0.8952 - val_loss: 0.7816 - val_accuracy: 0.7407\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.8667\n",
      "Epoch 26: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.4117 - accuracy: 0.8667 - val_loss: 0.8804 - val_accuracy: 0.6296\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9048\n",
      "Epoch 27: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.2925 - accuracy: 0.9048 - val_loss: 0.9083 - val_accuracy: 0.6296\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.9238\n",
      "Epoch 28: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.2993 - accuracy: 0.9238 - val_loss: 0.8289 - val_accuracy: 0.7407\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9238\n",
      "Epoch 29: val_accuracy did not improve from 0.77778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 126ms/step - loss: 0.2926 - accuracy: 0.9238 - val_loss: 1.3057 - val_accuracy: 0.5926\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.9333\n",
      "Epoch 30: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2678 - accuracy: 0.9333 - val_loss: 0.8049 - val_accuracy: 0.7407\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9333\n",
      "Epoch 31: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.2308 - accuracy: 0.9333 - val_loss: 0.7973 - val_accuracy: 0.7407\n",
      "Epoch 32/50\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.1800 - accuracy: 0.9688\n",
      "Epoch 32: val_accuracy did not improve from 0.77778\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2045 - accuracy: 0.9524 - val_loss: 1.9169 - val_accuracy: 0.4815\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n",
    "checkpoint = ModelCheckpoint(\"sentiment-analysis-model.h5\", verbose=1, monitor='val_accuracy', mode='max', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "hist = model.fit(Xtrain_emb, Ytrain_oht, batch_size=24, epochs=50, validation_split=0.2, callbacks=[earlystop, checkpoint], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_oht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
