{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-e34972428f84>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  X = pd.read_csv(\"../Datasets/emojified_text/emojify_train_x.csv\", header=None, sep=\"' '\")\n",
      "<ipython-input-152-e34972428f84>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  Xt = pd.read_csv(\"../Datasets/emojified_text/emojiy_test_x.csv\", header=None, sep=\"' '\")\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"../Datasets/emojified_text/emojify_train_x.csv\", header=None, sep=\"' '\")\n",
    "Y = pd.read_csv(\"../Datasets/emojified_text/Emojify_Y_train.csv\", header=None, sep=' ')\n",
    "\n",
    "Xt = pd.read_csv(\"../Datasets/emojified_text/emojiy_test_x.csv\", header=None, sep=\"' '\")\n",
    "Yt = pd.read_csv(\"../Datasets/emojified_text/emojiy_y_test.csv\", header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.asarray(X, dtype=str).reshape((-1,1))\n",
    "Ytrain = np.asarray(Y, dtype=int).reshape((-1,1))\n",
    "\n",
    "Xtest = np.asarray(Xt, dtype=str).reshape((-1,1))\n",
    "Ytest = Yt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_idx = {}\n",
    "\n",
    "with open(\"../Datasets/glove.6B.50d.txt/glove.6B.50d.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word_values = line.split()\n",
    "        word = word_values[0]\n",
    "        values = np.asarray(word_values[1:], dtype='float')\n",
    "        embedding_idx[word] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    \"0\": \":red_heart:\",\n",
    "    \"1\": \":baseball:\",\n",
    "    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "    \"3\": \":disappointed_face:\",\n",
    "    \"4\": \":fork_and_knife:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❤️'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(emoji_dict[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sentences in embedding format\n",
    "def data_embedding(X):\n",
    "    datasize = X.shape[0]\n",
    "    maxlen = 10 # sentences will be clipped after 10 words\n",
    "    \n",
    "    embed_data = list()\n",
    "    for sent in X:\n",
    "        sent = sent.split()\n",
    "        embed_sent = list()\n",
    "        for w_idx in range(maxlen):\n",
    "            try:\n",
    "                word = sent[w_idx].lower()\n",
    "                embed_sent.append(embedding_idx[word])\n",
    "            except:\n",
    "                embed_sent.append(np.zeros((50,)))\n",
    "                \n",
    "        embed_data.append(np.asarray(embed_sent))\n",
    "    \n",
    "    return np.asarray(embed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_emb = data_embedding(Xtrain[:,0])\n",
    "Xtest_emb = data_embedding(Xtest[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'never talk to me again\""
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RNN/LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 145       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,405\n",
      "Trainable params: 31,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(10, 50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(28,  activation='relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-f3586019f1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentiment-analysis-model.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mZ:\\Google\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"Z:\\Google\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', mode='max', patience=2)\n",
    "checkpoint = ModelCheckpoint(\"sentiment-analysis-model.h5\", verbose=1, monitor='val_accuracy', mode='max', save_weights_only=True, )\n",
    "\n",
    "hist = model.fit(Xtrain_emb, Ytrain, batch_size=10, epochs=20, callbacks=[earlystop, checkpoint], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert Ytrain into one-hot format\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Ytrain_oht = to_categorical(Ytrain)\n",
    "Ytest_oht = to_categorical(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5547 - accuracy: 0.3333\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25926, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 34s 749ms/step - loss: 1.5547 - accuracy: 0.3333 - val_loss: 1.6162 - val_accuracy: 0.2593\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4831 - accuracy: 0.3714\n",
      "Epoch 2: val_accuracy did not improve from 0.25926\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 1.4831 - accuracy: 0.3714 - val_loss: 1.6211 - val_accuracy: 0.2593\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 0.4000\n",
      "Epoch 3: val_accuracy improved from 0.25926 to 0.29630, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 1.4456 - accuracy: 0.4000 - val_loss: 1.5646 - val_accuracy: 0.2963\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3673 - accuracy: 0.4571\n",
      "Epoch 4: val_accuracy did not improve from 0.29630\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 1.3673 - accuracy: 0.4571 - val_loss: 1.4968 - val_accuracy: 0.1852\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2917 - accuracy: 0.5619\n",
      "Epoch 5: val_accuracy did not improve from 0.29630\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 1.2917 - accuracy: 0.5619 - val_loss: 1.4941 - val_accuracy: 0.2222\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1961 - accuracy: 0.5524\n",
      "Epoch 6: val_accuracy did not improve from 0.29630\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 1.1961 - accuracy: 0.5524 - val_loss: 1.5483 - val_accuracy: 0.1481\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1274 - accuracy: 0.5810\n",
      "Epoch 7: val_accuracy did not improve from 0.29630\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 1.1274 - accuracy: 0.5810 - val_loss: 1.4885 - val_accuracy: 0.2222\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.0676 - accuracy: 0.5810\n",
      "Epoch 8: val_accuracy improved from 0.29630 to 0.40741, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0676 - accuracy: 0.5810 - val_loss: 1.3387 - val_accuracy: 0.4074\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9255 - accuracy: 0.6762\n",
      "Epoch 9: val_accuracy improved from 0.40741 to 0.48148, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.9255 - accuracy: 0.6762 - val_loss: 1.2706 - val_accuracy: 0.4815\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.7048\n",
      "Epoch 10: val_accuracy did not improve from 0.48148\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.8988 - accuracy: 0.7048 - val_loss: 1.2235 - val_accuracy: 0.4815\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7596 - accuracy: 0.7905\n",
      "Epoch 11: val_accuracy improved from 0.48148 to 0.62963, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.7596 - accuracy: 0.7905 - val_loss: 1.1015 - val_accuracy: 0.6296\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7495 - accuracy: 0.7714\n",
      "Epoch 12: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.7495 - accuracy: 0.7714 - val_loss: 1.1315 - val_accuracy: 0.5185\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7714\n",
      "Epoch 13: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.6676 - accuracy: 0.7714 - val_loss: 1.2826 - val_accuracy: 0.4074\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7905\n",
      "Epoch 14: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.6625 - accuracy: 0.7905 - val_loss: 1.1476 - val_accuracy: 0.4815\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.8667\n",
      "Epoch 15: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.5464 - accuracy: 0.8667 - val_loss: 1.5961 - val_accuracy: 0.4815\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.7429\n",
      "Epoch 16: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.7050 - accuracy: 0.7429 - val_loss: 1.5128 - val_accuracy: 0.4074\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.7524\n",
      "Epoch 17: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.5758 - accuracy: 0.7524 - val_loss: 1.3728 - val_accuracy: 0.4815\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.8190\n",
      "Epoch 18: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.5336 - accuracy: 0.8190 - val_loss: 1.2104 - val_accuracy: 0.5926\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.8476\n",
      "Epoch 19: val_accuracy did not improve from 0.62963\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.4844 - accuracy: 0.8476 - val_loss: 1.2540 - val_accuracy: 0.5926\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8190\n",
      "Epoch 20: val_accuracy improved from 0.62963 to 0.70370, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.5107 - accuracy: 0.8190 - val_loss: 1.0017 - val_accuracy: 0.7037\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8952\n",
      "Epoch 21: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.3725 - accuracy: 0.8952 - val_loss: 1.0561 - val_accuracy: 0.7037\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8857\n",
      "Epoch 22: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.4075 - accuracy: 0.8857 - val_loss: 1.0882 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8952\n",
      "Epoch 23: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.3387 - accuracy: 0.8952 - val_loss: 1.4956 - val_accuracy: 0.5185\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8667\n",
      "Epoch 24: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.4281 - accuracy: 0.8667 - val_loss: 1.0139 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.9143\n",
      "Epoch 25: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.3344 - accuracy: 0.9143 - val_loss: 1.0016 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8571\n",
      "Epoch 26: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.4061 - accuracy: 0.8571 - val_loss: 1.4253 - val_accuracy: 0.5185\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9524\n",
      "Epoch 27: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.2116 - accuracy: 0.9524 - val_loss: 1.4189 - val_accuracy: 0.4815\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9238\n",
      "Epoch 28: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.2730 - accuracy: 0.9238 - val_loss: 1.3176 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8667\n",
      "Epoch 29: val_accuracy did not improve from 0.70370\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.3455 - accuracy: 0.8667 - val_loss: 1.1857 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9143\n",
      "Epoch 30: val_accuracy improved from 0.70370 to 0.74074, saving model to sentiment-analysis-model.h5\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.2267 - accuracy: 0.9143 - val_loss: 1.0584 - val_accuracy: 0.7407\n",
      "Epoch 31/100\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.2144 - accuracy: 0.9271\n",
      "Epoch 31: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2144 - accuracy: 0.9333 - val_loss: 1.0470 - val_accuracy: 0.7037\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9619\n",
      "Epoch 32: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1390 - accuracy: 0.9619 - val_loss: 1.2935 - val_accuracy: 0.5926\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9238\n",
      "Epoch 33: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2309 - accuracy: 0.9238 - val_loss: 1.1248 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8952\n",
      "Epoch 34: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3059 - accuracy: 0.8952 - val_loss: 1.7129 - val_accuracy: 0.5556\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.9143\n",
      "Epoch 35: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.2675 - accuracy: 0.9143 - val_loss: 1.1700 - val_accuracy: 0.6296\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9810\n",
      "Epoch 36: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0977 - accuracy: 0.9810 - val_loss: 1.6621 - val_accuracy: 0.5926\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9048\n",
      "Epoch 37: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.2698 - accuracy: 0.9048 - val_loss: 1.4277 - val_accuracy: 0.5926\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9619\n",
      "Epoch 38: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1325 - accuracy: 0.9619 - val_loss: 1.2555 - val_accuracy: 0.6296\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9905\n",
      "Epoch 39: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0869 - accuracy: 0.9905 - val_loss: 1.2786 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9714\n",
      "Epoch 40: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.1185 - accuracy: 0.9714 - val_loss: 1.4671 - val_accuracy: 0.5556\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9714\n",
      "Epoch 41: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 1.3043 - val_accuracy: 0.6296\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9714\n",
      "Epoch 42: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0881 - accuracy: 0.9714 - val_loss: 1.1769 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9810\n",
      "Epoch 43: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0786 - accuracy: 0.9810 - val_loss: 1.7169 - val_accuracy: 0.5185\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9429\n",
      "Epoch 44: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1761 - accuracy: 0.9429 - val_loss: 1.2967 - val_accuracy: 0.6296\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9905\n",
      "Epoch 45: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0509 - accuracy: 0.9905 - val_loss: 1.6140 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.8857\n",
      "Epoch 46: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3239 - accuracy: 0.8857 - val_loss: 1.2207 - val_accuracy: 0.7037\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9810\n",
      "Epoch 47: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 1.2897 - val_accuracy: 0.7037\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.7037\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 0.74074\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.5071 - val_accuracy: 0.5926\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', mode='max', patience=20)\n",
    "checkpoint = ModelCheckpoint(\"sentiment-analysis-model.h5\", verbose=1, monitor='val_accuracy', mode='max', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "hist = model.fit(Xtrain_emb, Ytrain_oht, batch_size=24, epochs=100, validation_split=0.2, callbacks=[earlystop, checkpoint], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_oht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 64)            29440     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 145       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,429\n",
      "Trainable params: 64,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stack_model = Sequential()\n",
    "stack_model.add(LSTM(64, input_shape=(10, 50), return_sequences=True))\n",
    "stack_model.add(LSTM(64, return_sequences=False))\n",
    "stack_model.add(Dropout(0.2))\n",
    "stack_model.add(Dense(28,  activation='relu'))\n",
    "stack_model.add(Dense(5))\n",
    "stack_model.add(Activation('softmax'))\n",
    "stack_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "stack_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 22s 2s/step - loss: 1.6052 - accuracy: 0.2273 - val_loss: 1.5975 - val_accuracy: 0.1818\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.5477 - accuracy: 0.3636 - val_loss: 1.5710 - val_accuracy: 0.2576\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 1.5255 - accuracy: 0.3182 - val_loss: 1.5617 - val_accuracy: 0.2879\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 1.4969 - accuracy: 0.3485 - val_loss: 1.5386 - val_accuracy: 0.3636\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 192ms/step - loss: 1.4739 - accuracy: 0.3788 - val_loss: 1.5041 - val_accuracy: 0.3485\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.4089 - accuracy: 0.3636 - val_loss: 1.4826 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 1.3217 - accuracy: 0.5000 - val_loss: 1.4175 - val_accuracy: 0.4091\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 1.2684 - accuracy: 0.5455 - val_loss: 1.3455 - val_accuracy: 0.3939\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 1.2219 - accuracy: 0.5000 - val_loss: 1.2949 - val_accuracy: 0.4848\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 191ms/step - loss: 1.0466 - accuracy: 0.6515 - val_loss: 1.2960 - val_accuracy: 0.4545\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.9938 - accuracy: 0.5455 - val_loss: 1.2499 - val_accuracy: 0.5455\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.9237 - accuracy: 0.6970 - val_loss: 1.1817 - val_accuracy: 0.4697\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 1.0318 - accuracy: 0.4848 - val_loss: 1.1608 - val_accuracy: 0.5455\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.7563 - accuracy: 0.7424 - val_loss: 1.1952 - val_accuracy: 0.5455\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 0.8156 - accuracy: 0.7273 - val_loss: 1.1089 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 194ms/step - loss: 0.6991 - accuracy: 0.8030 - val_loss: 1.1939 - val_accuracy: 0.5758\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 0.8211 - accuracy: 0.6818 - val_loss: 1.1104 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.5361 - accuracy: 0.8788 - val_loss: 1.1487 - val_accuracy: 0.6212\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.5495 - accuracy: 0.8333 - val_loss: 1.4030 - val_accuracy: 0.5152\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 193ms/step - loss: 0.5183 - accuracy: 0.8788 - val_loss: 1.1084 - val_accuracy: 0.6212\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 313ms/step - loss: 0.4608 - accuracy: 0.8788 - val_loss: 1.1913 - val_accuracy: 0.6515\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.5425 - accuracy: 0.8182 - val_loss: 1.4772 - val_accuracy: 0.5152\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.4429 - accuracy: 0.8333 - val_loss: 1.1924 - val_accuracy: 0.6061\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.2664 - accuracy: 0.9545 - val_loss: 1.2214 - val_accuracy: 0.6364\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.2323 - accuracy: 0.9697 - val_loss: 1.2656 - val_accuracy: 0.6212\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.2627 - accuracy: 0.9242 - val_loss: 1.3596 - val_accuracy: 0.6364\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.3129 - accuracy: 0.9091 - val_loss: 1.2081 - val_accuracy: 0.6212\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.1766 - accuracy: 0.9697 - val_loss: 1.5006 - val_accuracy: 0.6364\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.1683 - accuracy: 0.9545 - val_loss: 1.4628 - val_accuracy: 0.6061\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 0.4139 - accuracy: 0.8485 - val_loss: 1.4502 - val_accuracy: 0.5758\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1779 - accuracy: 0.9545 - val_loss: 1.2423 - val_accuracy: 0.6515\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.1428 - accuracy: 0.9697 - val_loss: 1.3751 - val_accuracy: 0.5606\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 190ms/step - loss: 0.2912 - accuracy: 0.8636 - val_loss: 1.8067 - val_accuracy: 0.5303\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.3466 - accuracy: 0.8485 - val_loss: 1.4019 - val_accuracy: 0.6364\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0915 - accuracy: 0.9697 - val_loss: 1.3979 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.1204 - accuracy: 0.9697 - val_loss: 1.3595 - val_accuracy: 0.5909\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.0702 - accuracy: 0.9848 - val_loss: 1.5190 - val_accuracy: 0.6212\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', mode='max', patience=20)\n",
    "checkpoint = ModelCheckpoint(\"sentiment-analysis-model.h5\", verbose=0, monitor='val_accuracy', mode='max', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "hist = stack_model.fit(Xtrain_emb, Ytrain_oht, batch_size=24, epochs=100, validation_split=0.5, callbacks=[earlystop, checkpoint], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
